#Step_1:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

#Step_2:
# Replace 'your_stock_data.csv' with the path to your CSV file containing historical stock prices.
data = pd.read_csv('your_stock_data.csv')

# Extract the 'Close' price column as the target variable to predict.
data = data[['Close']].values

# Normalize the data to the range [0, 1]
scaler = MinMaxScaler()
data = scaler.fit_transform(data)

#Step_3:
def create_sequences(data, sequence_length):
    X, y = [], []
    for i in range(len(data) - sequence_length):
        X.append(data[i : i + sequence_length])
        y.append(data[i + sequence_length])
    return np.array(X), np.array(y)

# Define the length of the input sequence (number of time steps to consider for prediction).
sequence_length = 60

# Create sequences for training.
X, y = create_sequences(data, sequence_length)

#Step_4:
# You can modify the split_ratio as desired (e.g., 0.8 for 80% training and 20% testing).
split_ratio = 0.8
split_index = int(split_ratio * len(X))

X_train, X_test = X[:split_index], X[split_index:]
y_train, y_test = y[:split_index], y[split_index:]

#Step_5:
model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(sequence_length, 1)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')
model.fit(X_train, y_train, epochs=50, batch_size=64)

#Step_6:
# Predict on the test set.
predictions = model.predict(X_test)

# Inverse the normalization to get the actual stock prices.
predictions = scaler.inverse_transform(predictions)
y_test = scaler.inverse_transform(y_test)

# Plot the results.
plt.figure(figsize=(12, 6))
plt.plot(predictions, label='Predicted')
plt.plot(y_test, label='True')
plt.legend()
plt.show()